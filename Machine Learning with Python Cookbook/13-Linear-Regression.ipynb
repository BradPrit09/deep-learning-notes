{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem : You want to train a model that represents a linear relationship between the feature and target vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Load data with only two features\n",
    "boston = load_boston()\n",
    "features = boston.data[:,0:2]\n",
    "target = boston.target\n",
    "\n",
    "# Create linear regression\n",
    "regression = LinearRegression()\n",
    "\n",
    "# Fit the linear regression\n",
    "model = regression.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.485628113468223"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the intercept\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And βˆ1 and βˆ2 are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.35207832,  0.11610909])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the feature coefficients\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First value in the target vector multiplied by 1000\n",
    "target[0]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24573.366631705547"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the target value of the first observation, multiplied by 1000\n",
    "model.predict(features)[0]*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad! Our model was only off by $573.36!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the coefficients of the model are the effect of a one-unit change on the target vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-352.07831564026765"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First coefficient multiplied by 1000\n",
    "# the first feature in our solution is the number of crimes per resident\n",
    "model.coef_[0]*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This says that every single crime per capita will decrease the price of the house by approximately $352!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Interactive Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem : You have a feature whose effect on the target variable depends on another feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Load data with only two features\n",
    "boston = load_boston()\n",
    "\n",
    "features = boston.data[:,0:2]\n",
    "target = boston.target\n",
    "\n",
    "# Create interaction term\n",
    "interaction = PolynomialFeatures(degree=3, # the degree parameter determines the maximum number of features to create interaction terms from\n",
    "                                 include_bias=False,  #  By default, PolynomialFeatures will add a feature containing ones called a bias\n",
    "                                 interaction_only=True) # interaction_only=True tells PolynomialFeatures to only return interaction terms\n",
    "\n",
    "features_interaction = interaction.fit_transform(features)\n",
    "\n",
    "# Create linear regression\n",
    "regression = LinearRegression()\n",
    "\n",
    "# Fit the linear regression\n",
    "model = regression.fit(features_interaction, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is the interaction of putting sugar in the coffee and stirring the coffee (sugar=1, stirred=1) that will make a coffee taste sweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effects of sugar and stir on sweetness are dependent on each other. In this case we say there is an interaction effect between the features sugar and stirred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.32000000e-03,   1.80000000e+01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the feature values for first observation\n",
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "\n",
    "# For each observation, multiply the values of the first and second feature\n",
    "interaction_term = np.multiply(features[:, 0], features[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11376"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View interaction term for first observation\n",
    "interaction_term[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " from our solution by checking to see if the first observation’s feature values and interaction term value match our manually calculated version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.32000000e-03,   1.80000000e+01,   1.13760000e-01])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the values of the first observation\n",
    "features_interaction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Nonlinear Relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem : You want to model a nonlinear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Load data with one feature\n",
    "boston = load_boston()\n",
    "features = boston.data[:,0:1]\n",
    "target = boston.target\n",
    "\n",
    "# Create polynomial features x^2 and x^3\n",
    "polynomial = PolynomialFeatures(degree=3, #!!!!!!!!!!!! degree\n",
    "                                include_bias=False) # !!!! do not include extra variable called bias for each feature \n",
    "features_polynomial = polynomial.fit_transform(features)\n",
    "\n",
    "# Create linear regression\n",
    "regression = LinearRegression()\n",
    "\n",
    "# Fit the linear regression\n",
    "model = regression.fit(features_polynomial, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do not change how the linear regression fits the model, but rather only add polynomial features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more of these new features we add, the more flexible the “line” created by our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00632])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first observation\n",
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.99424000e-05])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first observation raised to the second power, x^2\n",
    "features[0]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.52435968e-07])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first observation raised to the third power, x^3\n",
    "features[0]**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.32000000e-03,   3.99424000e-05,   2.52435968e-07])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first observation's values for x, x^2, and x^3 from PolynomialFeatures since d = 3\n",
    "features_polynomial[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Variance with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem : You want to reduce the variance of your linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a learning algorithm that includes a shrinkage penalty (also called regularization) like `ridge` regression and `lasso` regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "boston = load_boston()\n",
    "features = boston.data\n",
    "target = boston.target\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# Create ridge regression with an alpha value\n",
    "regression = Ridge(alpha=0.5)\n",
    "\n",
    "# Fit the linear regression\n",
    "model = regression.fit(features_standardized, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In standard linear regression the model trains to minimize the sum of squared error between the true (yi) and prediction, (yˆi) target values, or residual sum of squares (RSS).\n",
    "\n",
    "$$ RSS = \\sum_{i=1}^n (y_i−\\widehat{y}_i)^2 $$\n",
    "\n",
    "the shrinkage penalty is a tuning hyperparameter multiplied by the squared sum of all coefficients:\n",
    "\n",
    "$$ RSS + \\alpha \\sum_{j=1}^p \\widehat{β}_j^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lasso is similar, except the shrinkage penalty is a tuning hyperparameter multiplied by the sum of the absolute value of all coefficients\n",
    "\n",
    "$$ \\frac{1}{2n} RSS + \\alpha \\sum_{j=1}^p \\| \\widehat{β}_j\\| $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Regardless of which one we use, both ridge and lasso regressions can penalize large or complex models by including coefficient values in the loss function we are trying to minimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with higher values of $\\alpha$ creating simpler models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.91987132,  1.06646104,  0.11738487,  0.68512693, -2.02901013,\n",
       "        2.68275376,  0.01315848, -3.07733968,  2.59153764, -2.0105579 ,\n",
       "       -2.05238455,  0.84884839, -3.73066646])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Create ridge regression with three alpha values\n",
    "regr_cv = RidgeCV(alphas=[0.1, 1.0, 10.0]) # L2 PENALTY regularization\n",
    "\n",
    "# Fit the linear regression\n",
    "model_cv = regr_cv.fit(features_standardized, target)\n",
    "\n",
    "# View coefficients\n",
    "model_cv.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr_cv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "because in linear regression the value of the coefficients is partially determined by the scale of the feature, and in regularized models all coefficients are summed together, **we must make sure to standardize the feature prior to training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Features with Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem : You want to simplify your linear regression model by reducing the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Load data\n",
    "boston = load_boston()\n",
    "features = boston.data\n",
    "target = boston.target\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# Create lasso regression with alpha value\n",
    "regression = Lasso(alpha=0.5) # L1 PENALTY regularization\n",
    "\n",
    "# Fit the linear regression\n",
    "model = regression.fit(features_standardized, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it can shrink the coefficients of a model to zero, effectively reducing the number of features in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "many of the coefficients are 0 while using $\\alpha = 0.5$, meaning their corresponding features are not used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11526463,  0.        , -0.        ,  0.39707879, -0.        ,\n",
       "        2.97425861, -0.        , -0.17056942, -0.        , -0.        ,\n",
       "       -1.59844856,  0.54313871, -3.66614361])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View coefficients\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.,  0., -0.,  0., -0.,  0., -0.,  0., -0., -0., -0.,  0., -0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create lasso regression with a high alpha\n",
    "regression_a10 = Lasso(alpha=10)\n",
    "model_a10 = regression_a10.fit(features_standardized, target)\n",
    "model_a10.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This lets us REDUCE VARIANCE while improving the INTERPRETABILITY of our model (since fewer features is easier to explain).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
