{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n",
      "Loading dataset from disk.\n"
     ]
    }
   ],
   "source": [
    "_, (train, valid, test), _ = dc.molnet.load_tox21()\n",
    "train_X, train_y, train_w = train.X, train.y, train.w\n",
    "valid_X, valid_y, valid_w = valid.X, valid.y, valid.w\n",
    "test_X, test_y, test_w = test.X, test.y, test.w\n",
    "\n",
    "# Remove extra tasks\n",
    "train_y = train_y[:, 0]\n",
    "valid_y = valid_y[:, 0]\n",
    "test_y = test_y[:, 0]\n",
    "train_w = train_w[:, 0]\n",
    "valid_w = valid_w[:, 0]\n",
    "test_w = test_w[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to fit model on training set.\n",
      "Weighted train Classification Accuracy: 0.988575\n",
      "Weighted valid Classification Accuracy: 0.664234\n",
      "Weighted test Classification Accuracy: 0.664475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Generate tensorflow graph\n",
    "sklearn_model = RandomForestClassifier(class_weight=\"balanced\", n_estimators=50)\n",
    "print(\"About to fit model on training set.\")\n",
    "sklearn_model.fit(train_X, train_y)\n",
    "\n",
    "train_y_pred = sklearn_model.predict(train_X)\n",
    "valid_y_pred = sklearn_model.predict(valid_X)\n",
    "test_y_pred = sklearn_model.predict(test_X)\n",
    "\n",
    "weighted_score = accuracy_score(train_y, train_y_pred, sample_weight=train_w)\n",
    "print(\"Weighted train Classification Accuracy: %f\" % weighted_score)\n",
    "\n",
    "weighted_score = accuracy_score(valid_y, valid_y_pred, sample_weight=valid_w)\n",
    "print(\"Weighted valid Classification Accuracy: %f\" % weighted_score)\n",
    "\n",
    "weighted_score = accuracy_score(test_y, test_y_pred, sample_weight=test_w)\n",
    "print(\"Weighted test Classification Accuracy: %f\" % weighted_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graduate Student Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_tox21_hyperparams(n_hidden=50, n_layers=1, learning_rate=.001,\n",
    "                           dropout_prob=0.5, n_epochs=45, batch_size=100,\n",
    "                           weight_positives=True):\n",
    "\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"Model hyperparameters\")\n",
    "    print(\"n_hidden = %d\" % n_hidden)\n",
    "    print(\"n_layers = %d\" % n_layers)\n",
    "    print(\"learning_rate = %f\" % learning_rate)\n",
    "    print(\"n_epochs = %d\" % n_epochs)\n",
    "    print(\"batch_size = %d\" % batch_size)\n",
    "    print(\"weight_positives = %s\" % str(weight_positives))\n",
    "    print(\"dropout_prob = %f\" % dropout_prob)\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"---------------------------------------------\")\n",
    "\n",
    "    d = 1024\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "\n",
    "        # Generate tensorflow graph\n",
    "        with tf.name_scope(\"placeholders\"):\n",
    "            x = tf.placeholder(tf.float32, (None, d))\n",
    "            y = tf.placeholder(tf.float32, (None,))\n",
    "            w = tf.placeholder(tf.float32, (None,))\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "        for layer in range(n_layers):\n",
    "              with tf.name_scope(\"layer-%d\" % layer):\n",
    "                W = tf.Variable(tf.random_normal((d, n_hidden)))\n",
    "                b = tf.Variable(tf.random_normal((n_hidden,)))\n",
    "                x_hidden = tf.nn.relu(tf.matmul(x, W) + b)\n",
    "                # Apply dropout\n",
    "                x_hidden = tf.nn.dropout(x_hidden, keep_prob)\n",
    "        with tf.name_scope(\"output\"):\n",
    "            W = tf.Variable(tf.random_normal((n_hidden, 1)))\n",
    "            b = tf.Variable(tf.random_normal((1,)))\n",
    "            y_logit = tf.matmul(x_hidden, W) + b\n",
    "            # the sigmoid gives the class probability of 1\n",
    "            y_one_prob = tf.sigmoid(y_logit)\n",
    "            # Rounding P(y=1) will give the correct prediction.\n",
    "            y_pred = tf.round(y_one_prob)\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            # Compute the cross-entropy term for each datapoint\n",
    "            y_expand = tf.expand_dims(y, 1)\n",
    "            entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=y_logit, labels=y_expand)\n",
    "            # Multiply by weights\n",
    "            if weight_positives:\n",
    "                w_expand = tf.expand_dims(w, 1)\n",
    "                entropy = w_expand * entropy\n",
    "            \n",
    "            # Sum all contributions\n",
    "            l = tf.reduce_sum(entropy)\n",
    "\n",
    "        with tf.name_scope(\"optim\"):\n",
    "            train_op = tf.train.AdamOptimizer(learning_rate).minimize(l)\n",
    "\n",
    "        with tf.name_scope(\"summaries\"):\n",
    "            tf.summary.scalar(\"loss\", l)\n",
    "            merged = tf.summary.merge_all()\n",
    "\n",
    "        hyperparam_str = \"d-%d-hidden-%d-lr-%f-n_epochs-%d-batch_size-%d-weight_pos-%s\" % (d, n_hidden, learning_rate, n_epochs, batch_size, str(weight_positives))\n",
    "        train_writer = tf.summary.FileWriter('/tmp/fcnet-func-' + hyperparam_str, tf.get_default_graph())\n",
    "        N = train_X.shape[0]\n",
    "        \n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        step = 0\n",
    "        for epoch in range(n_epochs):\n",
    "            pos = 0\n",
    "            while pos < N:\n",
    "                batch_X = train_X[pos:pos+batch_size]\n",
    "                batch_y = train_y[pos:pos+batch_size]\n",
    "                batch_w = train_w[pos:pos+batch_size]\n",
    "                \n",
    "                feed_dict = {x: batch_X, y: batch_y, w: batch_w, keep_prob: dropout_prob}\n",
    "                _, summary, loss = sess.run([train_op, merged, l], feed_dict=feed_dict)\n",
    "#             print(\"epoch %d, step %d, loss: %f\" % (epoch, step, loss))\n",
    "                train_writer.add_summary(summary, step)\n",
    "\n",
    "                step += 1\n",
    "                pos += batch_size\n",
    "\n",
    "            # Make Predictions (set keep_prob to 1.0 for predictions)\n",
    "            valid_y_pred = sess.run(y_pred, feed_dict={x: valid_X, keep_prob: 1.0})\n",
    "\n",
    "        weighted_score = accuracy_score(valid_y, valid_y_pred, sample_weight=valid_w)\n",
    "        print(\"Valid Weighted Classification Accuracy: %f\" % weighted_score)\n",
    "    return weighted_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 30\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 15\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.637976\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 30\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 15\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.630551\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 60\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 15\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.617199\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 60\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 15\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.607947\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 30\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 30\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.614236\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 30\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 30\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.661666\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 60\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 30\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.690197\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 60\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 30\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.675001\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 30\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 15\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.586101\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 30\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 15\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.622798\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 60\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 15\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.604243\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 60\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 15\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.660563\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 30\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 30\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.628691\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 30\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 30\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.628691\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 60\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 30\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.682048\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 60\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 30\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.696864\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 30\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 15\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.636857\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 30\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 15\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.690230\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 60\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 15\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.640923\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 60\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 15\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.662786\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 30\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 30\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.625727\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 30\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 30\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.658341\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 60\n",
      "n_layers = 1\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 30\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.649055\n",
      "All Scores\n",
      "---------------------------------------------\n",
      "Model hyperparameters\n",
      "n_hidden = 60\n",
      "n_layers = 2\n",
      "learning_rate = 0.001000\n",
      "n_epochs = 30\n",
      "batch_size = 100\n",
      "weight_positives = True\n",
      "dropout_prob = 0.500000\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Valid Weighted Classification Accuracy: 0.627950\n",
      "All Scores\n",
      "{(60, 30, 0.5, 1): [0.69019676478133385, 0.68204758125807663, 0.64905525573188017], (30, 15, 0.5, 1): [0.63797629807934364, 0.58610107480993634, 0.6368566544472869], (60, 15, 0.5, 1): [0.61719935650460211, 0.60424313768739646, 0.64092285487548462], (30, 30, 0.5, 1): [0.61423601704159947, 0.62869068825716801, 0.62572734879416536], (60, 30, 0.5, 2): [0.67500125870001459, 0.69686427857308975, 0.62794985339141729], (30, 15, 0.5, 2): [0.63055116675497547, 0.62279757466488606, 0.69023033011505719], (30, 30, 0.5, 2): [0.66166623111650291, 0.62869068825716801, 0.6583408655540558], (60, 15, 0.5, 2): [0.60794731201614971, 0.66056337015130773, 0.66278587474855966]}\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "n_reps = 3\n",
    "hidden_sizes = [30, 60]\n",
    "epochs = [15, 30]\n",
    "dropouts = [.5]\n",
    "num_layers = [1, 2]\n",
    "\n",
    "for rep in range(n_reps):\n",
    "    for n_epochs in epochs:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            for dropout in dropouts:\n",
    "                for n_layers in num_layers:\n",
    "                    score = eval_tox21_hyperparams(n_hidden=hidden_size, n_epochs=n_epochs, dropout_prob=dropout, n_layers=n_layers)\n",
    "                    if (hidden_size, n_epochs, dropout, n_layers) not in scores:\n",
    "                        scores[(hidden_size, n_epochs, dropout, n_layers)] = []\n",
    "                    scores[(hidden_size, n_epochs, dropout, n_layers)].append(score)\n",
    "\n",
    "                    print(\"All Scores\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Averaged over 3 repetitions\n",
      "{(30, 15, 0.5, 2): 0.6478596905116395, (30, 15, 0.5, 1): 0.62031134244552233, (60, 15, 0.5, 1): 0.62078844968916103, (30, 30, 0.5, 1): 0.62288468469764435, (60, 30, 0.5, 2): 0.66660513022150714, (60, 30, 0.5, 1): 0.67376653392376351, (30, 30, 0.5, 2): 0.64956592830924231, (60, 15, 0.5, 2): 0.64376551897200562}\n"
     ]
    }
   ],
   "source": [
    "avg_scores = {}\n",
    "for params, param_scores in scores.items():\n",
    "    avg_scores[params] = np.mean(np.array(param_scores))\n",
    "print(\"Scores Averaged over %d repetitions\" % n_reps)\n",
    "print(avg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.96140197e-05,   1.94962910e-03,   5.73339445e-03,\n",
       "         2.00852400e-06,   2.40747690e-04])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rates = 5\n",
    "learning_rates = 10**(-np.random.uniform(low=1, high=6, size=n_rates))\n",
    "learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
